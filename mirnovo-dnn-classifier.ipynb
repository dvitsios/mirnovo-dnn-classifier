{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "data = pd.read_csv('all_universal_animals_features.txt', sep='\\t')\n",
    "data.index = range(0, len(data))\n",
    "\n",
    "# shuffle data frame rows (optional)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspcet first 10 lines of raw data across all columns (in 3 parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part-1\n",
    "data.iloc[:5,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part-2\n",
    "data.iloc[:5,10:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part-3\n",
    "data.iloc[:5,23:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace YES/NO flags with 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'YES': 1, 'NO': 0}\n",
    "data = data.replace({'hits_on_mature_miR': label_mapping})\n",
    "y = data['hits_on_mature_miR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (data - data.min()) / (data.max() - data.min())\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing values (with median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_NaN = Imputer(missing_values=np.nan, strategy='median', axis=1)\n",
    "imputed_DF = pd.DataFrame(fill_NaN.fit_transform(data))\n",
    "imputed_DF.columns = data.columns\n",
    "imputed_DF.index = data.index\n",
    "data = imputed_DF\n",
    "\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-integrate TP label with the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TP'] = y\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8\n",
    "\n",
    "sample = np.random.choice(data.index, size=int(len(data)*split_ratio), replace=False)\n",
    "train_data, test_data = data.iloc[sample], data.drop(sample)\n",
    "\n",
    "print(\"Number of training samples is\", len(train_data))\n",
    "print(\"Number of testing samples is\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create np.arrays for X_train/test and y_train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_data.drop('TP', axis=1))\n",
    "y_train = np.array(keras.utils.to_categorical(train_data['TP'], 2))\n",
    "\n",
    "X_test = np.array(test_data.drop('TP', axis=1))\n",
    "y_test = np.array(keras.utils.to_categorical(test_data['TP'], 2))\n",
    "\n",
    "\n",
    "print(\"Number of rows in X_train: \", len(X_train))\n",
    "print(\"Number of rows in y_train: \", len(y_train))\n",
    "print(\"Number of rows in X_test\", len(X_test))\n",
    "print(\"Number of rows in y_test\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model using optimal parameters <span style='font-size:12px'>(found via GridSearchCV)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# create the model\n",
    "def create_model(optimizer='adam'):\n",
    "    \n",
    "    init_mode = 'he_normal'\n",
    "    reglr = 0.01\n",
    "#     optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    \n",
    "    # Building the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=regularizers.l2(reglr)))\n",
    "    model.add(Dropout(.4))\n",
    "    model.add(Dense(32, kernel_initializer=init_mode, activation='relu', kernel_regularizer=regularizers.l2(reglr)))\n",
    "    model.add(Dropout(.4))\n",
    "\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='acc', patience=2)] # do not apply without checking first with no callbacks\n",
    "\n",
    "out = model.fit(X_train, y_train, epochs=30, batch_size=128, verbose=1, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot training / validation loss and accuracy change at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = np.array(out.__dict__['epoch'])\n",
    "acc = np.array(out.__dict__['history']['acc'])\n",
    "loss = np.array(out.__dict__['history']['loss'])\n",
    "val_acc = np.array(out.__dict__['history']['val_acc'])\n",
    "val_loss = np.array(out.__dict__['history']['val_loss'])\n",
    "\n",
    "f = plt.figure(figsize=(7,5))\n",
    "plt.plot(epochs, loss, label='training')\n",
    "plt.plot(epochs, val_loss, label='validation')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "f = plt.figure(figsize=(7,5))\n",
    "plt.plot(epochs, acc, label='training')\n",
    "plt.plot(epochs, val_acc, label='validation')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "f.savefig(\"train_validation_loss.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model on the training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose=1)\n",
    "print(\"\\n Training Accuracy:\", train_score[1])\n",
    "test_score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"\\n Testing Accuracy:\", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y.values.argmax\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "p = model.predict_proba(X_test)\n",
    "\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred))\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))\n",
    "print()\n",
    "TN, FP, FN, TP = confusion_matrix(np.argmax(y_test, axis=1), y_pred).ravel()\n",
    "print(\"TP:\", TP)\n",
    "print(\"FN:\", FN)\n",
    "print(\"TN:\", TN)\n",
    "print(\"FP:\", FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect predicted positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = pd.concat([pd.DataFrame(y_test), pd.DataFrame(p)], axis=1)\n",
    "conc.columns = ['test_0', 'test_1', 'pred_0', 'pred_1']\n",
    "subdf = conc.loc[conc['test_1'] == 1]\n",
    "p = subdf.loc[subdf['pred_1'] >= 0.5]\n",
    "\n",
    "p[:15]\n",
    "res = subdf.loc[subdf['pred_1'] >= 0.5]\n",
    "res[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
