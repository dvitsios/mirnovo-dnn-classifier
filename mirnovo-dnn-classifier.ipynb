{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_seq_len</th>\n",
       "      <th>MainBody_length</th>\n",
       "      <th>avg_GC_cont</th>\n",
       "      <th>avg_ATcont_after3p</th>\n",
       "      <th>sum_all_reads</th>\n",
       "      <th>num_gap_bars</th>\n",
       "      <th>scale_rate_5p</th>\n",
       "      <th>num_mismatches_8mer</th>\n",
       "      <th>num_mism_in_MB</th>\n",
       "      <th>len_after_MB</th>\n",
       "      <th>...</th>\n",
       "      <th>hits_on_mature_miR</th>\n",
       "      <th>bracket_mirna_fraction</th>\n",
       "      <th>hairpin_size_estimate</th>\n",
       "      <th>loop_mirna_distance_estimate</th>\n",
       "      <th>loop_size_estimate</th>\n",
       "      <th>loops_in_hairpin</th>\n",
       "      <th>minimum_free_energy</th>\n",
       "      <th>mirna_bracket_discrepancy</th>\n",
       "      <th>mirna_bracket_majority</th>\n",
       "      <th>mirna_unmatched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.200000</td>\n",
       "      <td>19</td>\n",
       "      <td>0.413838</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-33.1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.954930</td>\n",
       "      <td>25</td>\n",
       "      <td>0.591125</td>\n",
       "      <td>0.081690</td>\n",
       "      <td>355</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>78.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-44.1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.946459</td>\n",
       "      <td>23</td>\n",
       "      <td>0.464437</td>\n",
       "      <td>0.015150</td>\n",
       "      <td>40866</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>61.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.291971</td>\n",
       "      <td>16</td>\n",
       "      <td>0.480594</td>\n",
       "      <td>0.072993</td>\n",
       "      <td>137</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.600000</td>\n",
       "      <td>26</td>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>65.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.105263</td>\n",
       "      <td>17</td>\n",
       "      <td>0.411624</td>\n",
       "      <td>0.192983</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.352941</td>\n",
       "      <td>15</td>\n",
       "      <td>0.651936</td>\n",
       "      <td>0.215687</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-35.5</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.666667</td>\n",
       "      <td>22</td>\n",
       "      <td>0.588274</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>61.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-33.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.363636</td>\n",
       "      <td>15</td>\n",
       "      <td>0.794733</td>\n",
       "      <td>0.252527</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-42.2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_seq_len  MainBody_length  avg_GC_cont  avg_ATcont_after3p  \\\n",
       "0    21.200000               19     0.413838            0.040000   \n",
       "1    26.954930               25     0.591125            0.081690   \n",
       "2    22.946459               23     0.464437            0.015150   \n",
       "3    19.291971               16     0.480594            0.072993   \n",
       "4    26.600000               26     0.509259            0.000000   \n",
       "5    22.000000               22     0.318182                 NaN   \n",
       "6    23.105263               17     0.411624            0.192983   \n",
       "7    20.352941               15     0.651936            0.215687   \n",
       "8    22.666667               22     0.588274            0.333330   \n",
       "9    19.363636               15     0.794733            0.252527   \n",
       "\n",
       "   sum_all_reads  num_gap_bars  scale_rate_5p  num_mismatches_8mer  \\\n",
       "0             50             8              8                    0   \n",
       "1            355             3              3                    0   \n",
       "2          40866             7              7                    0   \n",
       "3            137            12             12                    0   \n",
       "4              5             0              0                    0   \n",
       "5              8             0              0                    0   \n",
       "6             19             7              7                    0   \n",
       "7             17             4              4                    0   \n",
       "8              6             0              0                    0   \n",
       "9             33            11             11                    1   \n",
       "\n",
       "   num_mism_in_MB  len_after_MB       ...         hits_on_mature_miR  \\\n",
       "0               0             3       ...                         NO   \n",
       "1               0             8       ...                         NO   \n",
       "2               0             7       ...                        YES   \n",
       "3               0             8       ...                         NO   \n",
       "4               0             1       ...                         NO   \n",
       "5               0             0       ...                         NO   \n",
       "6               0            11       ...                         NO   \n",
       "7               0             9       ...                         NO   \n",
       "8               0             1       ...                        YES   \n",
       "9               0             6       ...                         NO   \n",
       "\n",
       "   bracket_mirna_fraction  hairpin_size_estimate  \\\n",
       "0                0.523810                   34.0   \n",
       "1                0.678571                   78.0   \n",
       "2                0.869565                   61.0   \n",
       "3                0.578947                   52.0   \n",
       "4                0.481481                   65.0   \n",
       "5                0.500000                   66.0   \n",
       "6                     NaN                    NaN   \n",
       "7                0.333333                   24.0   \n",
       "8                0.695652                   61.0   \n",
       "9                0.700000                   38.0   \n",
       "\n",
       "   loop_mirna_distance_estimate  loop_size_estimate  loops_in_hairpin  \\\n",
       "0                           0.0                 9.0               1.0   \n",
       "1                          10.0                 3.0               1.0   \n",
       "2                           6.0                 4.0               1.0   \n",
       "3                           0.0                 8.0               2.0   \n",
       "4                           7.0                 5.0               1.0   \n",
       "5                           0.0                12.0               2.0   \n",
       "6                           NaN                 NaN               NaN   \n",
       "7                           0.0                 5.0               1.0   \n",
       "8                           5.0                 6.0               1.0   \n",
       "9                           0.0                 7.0               1.0   \n",
       "\n",
       "   minimum_free_energy  mirna_bracket_discrepancy  mirna_bracket_majority  \\\n",
       "0                -33.1                   1.000000                    11.0   \n",
       "1                -44.1                   1.000000                    19.0   \n",
       "2                -31.0                   1.000000                    20.0   \n",
       "3                 -9.5                   1.000000                    11.0   \n",
       "4                -20.0                   1.000000                    13.0   \n",
       "5                 -8.1                   1.000000                    11.0   \n",
       "6                  NaN                        NaN                     NaN   \n",
       "7                -35.5                   0.636364                     7.0   \n",
       "8                -33.9                   1.000000                    16.0   \n",
       "9                -42.2                   1.000000                    14.0   \n",
       "\n",
       "   mirna_unmatched  \n",
       "0             10.0  \n",
       "1              9.0  \n",
       "2              3.0  \n",
       "3              8.0  \n",
       "4             14.0  \n",
       "5             11.0  \n",
       "6              NaN  \n",
       "7             10.0  \n",
       "8              7.0  \n",
       "9              6.0  \n",
       "\n",
       "[10 rows x 34 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "data = pd.read_csv('all_universal_animals_features.txt', sep='\\t')\n",
    "data.index = range(0, len(data))\n",
    "\n",
    "# shuffle data frame rows (optional)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspcet first 10 lines of raw data across all columns (in 3 parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_seq_len</th>\n",
       "      <th>MainBody_length</th>\n",
       "      <th>avg_GC_cont</th>\n",
       "      <th>avg_ATcont_after3p</th>\n",
       "      <th>sum_all_reads</th>\n",
       "      <th>num_gap_bars</th>\n",
       "      <th>scale_rate_5p</th>\n",
       "      <th>num_mismatches_8mer</th>\n",
       "      <th>num_mism_in_MB</th>\n",
       "      <th>len_after_MB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.633333</td>\n",
       "      <td>22</td>\n",
       "      <td>0.422747</td>\n",
       "      <td>0.333330</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.033557</td>\n",
       "      <td>17</td>\n",
       "      <td>0.496774</td>\n",
       "      <td>0.147650</td>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.060000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.406878</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.560000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.470763</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.461538</td>\n",
       "      <td>22</td>\n",
       "      <td>0.289826</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.800000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.577273</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_seq_len  MainBody_length  avg_GC_cont  avg_ATcont_after3p  \\\n",
       "0    21.633333               22     0.422747            0.333330   \n",
       "1    18.000000               18     0.555556                 NaN   \n",
       "2    18.033557               17     0.496774            0.147650   \n",
       "3    21.060000               21     0.406878            0.013333   \n",
       "4    28.000000               26     0.321429            0.312500   \n",
       "5    21.560000               20     0.470763            0.306667   \n",
       "6    17.000000               17     0.647059                 NaN   \n",
       "7    26.461538               22     0.289826            0.743590   \n",
       "8    20.800000               21     0.577273            0.300000   \n",
       "9    26.000000               26     0.307692                 NaN   \n",
       "\n",
       "   sum_all_reads  num_gap_bars  scale_rate_5p  num_mismatches_8mer  \\\n",
       "0             30             3              3                    0   \n",
       "1             35             0              0                    0   \n",
       "2            149             2              2                    0   \n",
       "3             50             0              0                    0   \n",
       "4              8             5              5                    2   \n",
       "5             25             1              1                    0   \n",
       "6             18             0              0                    0   \n",
       "7             13             4              4                    0   \n",
       "8              5             1              1                    0   \n",
       "9             10             0              0                    0   \n",
       "\n",
       "   num_mism_in_MB  len_after_MB  \n",
       "0               3             1  \n",
       "1               0             0  \n",
       "2               0             6  \n",
       "3               0             6  \n",
       "4               4             2  \n",
       "5               0             6  \n",
       "6               0             0  \n",
       "7               0             6  \n",
       "8               0             2  \n",
       "9               0             0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part-1\n",
    "data.iloc[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gap_droppin_len</th>\n",
       "      <th>gcs</th>\n",
       "      <th>ats</th>\n",
       "      <th>cpg</th>\n",
       "      <th>cwf</th>\n",
       "      <th>ce</th>\n",
       "      <th>cz</th>\n",
       "      <th>cm2</th>\n",
       "      <th>cm3</th>\n",
       "      <th>ct2</th>\n",
       "      <th>ct3</th>\n",
       "      <th>cl2</th>\n",
       "      <th>cl3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1.971130</td>\n",
       "      <td>0.984950</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.827174</td>\n",
       "      <td>0.648735</td>\n",
       "      <td>0.68750</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>1.854429</td>\n",
       "      <td>0.952438</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.863706</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>1.918927</td>\n",
       "      <td>0.746607</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.663564</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.977827</td>\n",
       "      <td>0.945460</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.896046</td>\n",
       "      <td>0.690444</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.186973</td>\n",
       "      <td>0.903083</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.864873</td>\n",
       "      <td>0.680643</td>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.007899</td>\n",
       "      <td>0.720583</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.597617</td>\n",
       "      <td>0.511808</td>\n",
       "      <td>0.28125</td>\n",
       "      <td>0.148026</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.487179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>1.809106</td>\n",
       "      <td>0.950753</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.831955</td>\n",
       "      <td>0.628926</td>\n",
       "      <td>0.68750</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2.215271</td>\n",
       "      <td>0.925051</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.875071</td>\n",
       "      <td>0.727286</td>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>2.049072</td>\n",
       "      <td>0.966832</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.893156</td>\n",
       "      <td>0.716180</td>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.902439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2.178934</td>\n",
       "      <td>0.766287</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.693673</td>\n",
       "      <td>0.627982</td>\n",
       "      <td>0.62500</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gap_droppin_len       gcs       ats       cpg       cwf        ce  \\\n",
       "0                0  0.111111  0.166667  0.450000  1.971130  0.984950   \n",
       "1                0  0.400000  0.250000  0.476190  1.854429  0.952438   \n",
       "2                3  0.800000  0.750000  1.111111  1.918927  0.746607   \n",
       "3                1  0.000000  0.384615  0.500000  1.977827  0.945460   \n",
       "4                0  0.000000  0.368421  0.500000  2.186973  0.903083   \n",
       "5                4  1.000000  0.454545  0.000000  2.007899  0.720583   \n",
       "6                0  0.272727  0.000000  0.392857  1.809106  0.950753   \n",
       "7                0  0.250000  0.000000  0.533333  2.215271  0.925051   \n",
       "8                0  0.076923  0.400000  0.309524  2.049072  0.966832   \n",
       "9                0  0.250000  0.777778  0.533333  2.178934  0.766287   \n",
       "\n",
       "         cz       cm2       cm3      ct2       ct3   cl2       cl3  \n",
       "0  0.420000  0.827174  0.648735  0.68750  0.578947  0.75  0.794872  \n",
       "1  0.375000  0.863706  0.625000  0.75000  0.656250  0.80  0.833333  \n",
       "2  0.375000  0.663564  0.604167  0.50000  0.406250  0.60  0.694444  \n",
       "3  0.403846  0.896046  0.690444  0.87500  0.828947  0.90  0.923077  \n",
       "4  0.509434  0.864873  0.680643  0.81250  0.617500  0.85  0.800000  \n",
       "5  0.456522  0.597617  0.511808  0.28125  0.148026  0.45  0.487179  \n",
       "6  0.361702  0.831955  0.628926  0.68750  0.641667  0.75  0.828571  \n",
       "7  0.491228  0.875071  0.727286  0.81250  0.687500  0.85  0.847826  \n",
       "8  0.425926  0.893156  0.716180  0.81250  0.773810  0.85  0.902439  \n",
       "9  0.520000  0.693673  0.627982  0.62500  0.416667  0.70  0.681818  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part-2\n",
    "data.iloc[:10,10:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident2rev_compl_clust</th>\n",
       "      <th>hits_on_mature_miR</th>\n",
       "      <th>bracket_mirna_fraction</th>\n",
       "      <th>hairpin_size_estimate</th>\n",
       "      <th>loop_mirna_distance_estimate</th>\n",
       "      <th>loop_size_estimate</th>\n",
       "      <th>loops_in_hairpin</th>\n",
       "      <th>minimum_free_energy</th>\n",
       "      <th>mirna_bracket_discrepancy</th>\n",
       "      <th>mirna_bracket_majority</th>\n",
       "      <th>mirna_unmatched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-33.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-19.4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-42.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>74</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-12.6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>71</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>68.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-22.6</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>71</td>\n",
       "      <td>NO</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ident2rev_compl_clust hits_on_mature_miR  bracket_mirna_fraction  \\\n",
       "0                     76                YES                0.904762   \n",
       "1                     75                 NO                     NaN   \n",
       "2                     79                YES                0.555556   \n",
       "3                     77                YES                0.714286   \n",
       "4                     59                 NO                0.666667   \n",
       "5                     69                YES                     NaN   \n",
       "6                     78                 NO                0.882353   \n",
       "7                     74                 NO                0.428571   \n",
       "8                     71                 NO                0.565217   \n",
       "9                     71                 NO                0.884615   \n",
       "\n",
       "   hairpin_size_estimate  loop_mirna_distance_estimate  loop_size_estimate  \\\n",
       "0                   60.0                           2.0                16.0   \n",
       "1                    NaN                           NaN                 NaN   \n",
       "2                   39.0                           4.0                 3.0   \n",
       "3                   60.0                           7.0                 3.0   \n",
       "4                   61.0                           3.0                 5.0   \n",
       "5                    NaN                           NaN                 NaN   \n",
       "6                   33.0                           0.0                 4.0   \n",
       "7                   61.0                           0.0                 5.0   \n",
       "8                   68.0                          15.0                 8.0   \n",
       "9                   68.0                           0.0                 7.0   \n",
       "\n",
       "   loops_in_hairpin  minimum_free_energy  mirna_bracket_discrepancy  \\\n",
       "0               1.0                -33.5                   1.000000   \n",
       "1               NaN                  NaN                        NaN   \n",
       "2               1.0                -19.4                   1.000000   \n",
       "3               1.0                -11.0                   1.000000   \n",
       "4               1.0                -15.2                   1.000000   \n",
       "5               NaN                  NaN                        NaN   \n",
       "6               1.0                -42.6                   1.000000   \n",
       "7               2.0                -12.6                   0.666667   \n",
       "8               1.0                -22.6                   0.722222   \n",
       "9               1.0                -18.2                   1.000000   \n",
       "\n",
       "   mirna_bracket_majority  mirna_unmatched  \n",
       "0                    19.0              2.0  \n",
       "1                     NaN              NaN  \n",
       "2                    10.0              8.0  \n",
       "3                    15.0              6.0  \n",
       "4                    18.0              9.0  \n",
       "5                     NaN              NaN  \n",
       "6                    15.0              2.0  \n",
       "7                    12.0             10.0  \n",
       "8                    13.0              5.0  \n",
       "9                    23.0              3.0  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part-3\n",
    "data.iloc[:10,23:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace YES/NO flags with 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'YES': 1, 'NO': 0}\n",
    "data = data.replace({'hits_on_mature_miR': label_mapping})\n",
    "y = data['hits_on_mature_miR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_seq_len</th>\n",
       "      <th>MainBody_length</th>\n",
       "      <th>avg_GC_cont</th>\n",
       "      <th>avg_ATcont_after3p</th>\n",
       "      <th>sum_all_reads</th>\n",
       "      <th>num_gap_bars</th>\n",
       "      <th>scale_rate_5p</th>\n",
       "      <th>num_mismatches_8mer</th>\n",
       "      <th>num_mism_in_MB</th>\n",
       "      <th>len_after_MB</th>\n",
       "      <th>...</th>\n",
       "      <th>hits_on_mature_miR</th>\n",
       "      <th>bracket_mirna_fraction</th>\n",
       "      <th>hairpin_size_estimate</th>\n",
       "      <th>loop_mirna_distance_estimate</th>\n",
       "      <th>loop_size_estimate</th>\n",
       "      <th>loops_in_hairpin</th>\n",
       "      <th>minimum_free_energy</th>\n",
       "      <th>mirna_bracket_discrepancy</th>\n",
       "      <th>mirna_bracket_majority</th>\n",
       "      <th>mirna_unmatched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.413838</td>\n",
       "      <td>0.050079</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.582071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912911</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.591125</td>\n",
       "      <td>0.102274</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.443182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.578872</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.464437</td>\n",
       "      <td>0.018967</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.274331</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.480594</td>\n",
       "      <td>0.091386</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.880051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.275862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.627660</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_seq_len  MainBody_length  avg_GC_cont  avg_ATcont_after3p  \\\n",
       "0     0.433333             0.36     0.413838            0.050079   \n",
       "1     0.912911             0.48     0.591125            0.102274   \n",
       "2     0.578872             0.44     0.464437            0.018967   \n",
       "3     0.274331             0.30     0.480594            0.091386   \n",
       "4     0.883333             0.50     0.509259            0.000000   \n",
       "\n",
       "   sum_all_reads  num_gap_bars  scale_rate_5p  num_mismatches_8mer  \\\n",
       "0       0.000004      0.205128       0.205128                  0.0   \n",
       "1       0.000034      0.076923       0.076923                  0.0   \n",
       "2       0.003959      0.179487       0.179487                  0.0   \n",
       "3       0.000013      0.307692       0.307692                  0.0   \n",
       "4       0.000000      0.000000       0.000000                  0.0   \n",
       "\n",
       "   num_mism_in_MB  len_after_MB       ...         hits_on_mature_miR  \\\n",
       "0             0.0      0.071429       ...                        0.0   \n",
       "1             0.0      0.190476       ...                        0.0   \n",
       "2             0.0      0.166667       ...                        1.0   \n",
       "3             0.0      0.190476       ...                        0.0   \n",
       "4             0.0      0.023810       ...                        0.0   \n",
       "\n",
       "   bracket_mirna_fraction  hairpin_size_estimate  \\\n",
       "0                0.523810               0.297872   \n",
       "1                0.678571               0.765957   \n",
       "2                0.869565               0.585106   \n",
       "3                0.578947               0.489362   \n",
       "4                0.481481               0.627660   \n",
       "\n",
       "   loop_mirna_distance_estimate  loop_size_estimate  loops_in_hairpin  \\\n",
       "0                      0.000000            0.112676          0.000000   \n",
       "1                      0.285714            0.028169          0.000000   \n",
       "2                      0.171429            0.042254          0.000000   \n",
       "3                      0.000000            0.098592          0.111111   \n",
       "4                      0.200000            0.056338          0.000000   \n",
       "\n",
       "   minimum_free_energy  mirna_bracket_discrepancy  mirna_bracket_majority  \\\n",
       "0             0.582071                        1.0                0.344828   \n",
       "1             0.443182                        1.0                0.620690   \n",
       "2             0.608586                        1.0                0.655172   \n",
       "3             0.880051                        1.0                0.344828   \n",
       "4             0.747475                        1.0                0.413793   \n",
       "\n",
       "   mirna_unmatched  \n",
       "0         0.344828  \n",
       "1         0.310345  \n",
       "2         0.103448  \n",
       "3         0.275862  \n",
       "4         0.482759  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (data - data.min()) / (data.max() - data.min())\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing values (with median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_seq_len</th>\n",
       "      <th>MainBody_length</th>\n",
       "      <th>avg_GC_cont</th>\n",
       "      <th>avg_ATcont_after3p</th>\n",
       "      <th>sum_all_reads</th>\n",
       "      <th>num_gap_bars</th>\n",
       "      <th>scale_rate_5p</th>\n",
       "      <th>num_mismatches_8mer</th>\n",
       "      <th>num_mism_in_MB</th>\n",
       "      <th>len_after_MB</th>\n",
       "      <th>...</th>\n",
       "      <th>hits_on_mature_miR</th>\n",
       "      <th>bracket_mirna_fraction</th>\n",
       "      <th>hairpin_size_estimate</th>\n",
       "      <th>loop_mirna_distance_estimate</th>\n",
       "      <th>loop_size_estimate</th>\n",
       "      <th>loops_in_hairpin</th>\n",
       "      <th>minimum_free_energy</th>\n",
       "      <th>mirna_bracket_discrepancy</th>\n",
       "      <th>mirna_bracket_majority</th>\n",
       "      <th>mirna_unmatched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.413838</td>\n",
       "      <td>0.050079</td>\n",
       "      <td>4.359565e-06</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.582071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912911</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.591125</td>\n",
       "      <td>0.102274</td>\n",
       "      <td>3.390773e-05</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.443182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.578872</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.464437</td>\n",
       "      <td>0.018967</td>\n",
       "      <td>3.958582e-03</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.274331</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.480594</td>\n",
       "      <td>0.091386</td>\n",
       "      <td>1.278806e-05</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.880051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.275862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.627660</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>2.906377e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.379310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.411624</td>\n",
       "      <td>0.241610</td>\n",
       "      <td>1.356309e-06</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.362745</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.651936</td>\n",
       "      <td>0.270034</td>\n",
       "      <td>1.162551e-06</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.551768</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.588274</td>\n",
       "      <td>0.417320</td>\n",
       "      <td>9.687922e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.280303</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.794733</td>\n",
       "      <td>0.316156</td>\n",
       "      <td>2.712618e-06</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.206897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_seq_len  MainBody_length  avg_GC_cont  avg_ATcont_after3p  \\\n",
       "0     0.433333             0.36     0.413838            0.050079   \n",
       "1     0.912911             0.48     0.591125            0.102274   \n",
       "2     0.578872             0.44     0.464437            0.018967   \n",
       "3     0.274331             0.30     0.480594            0.091386   \n",
       "4     0.883333             0.50     0.509259            0.000000   \n",
       "5     0.500000             0.42     0.318182            0.379310   \n",
       "6     0.592105             0.32     0.411624            0.241610   \n",
       "7     0.362745             0.28     0.651936            0.270034   \n",
       "8     0.555556             0.42     0.588274            0.417320   \n",
       "9     0.280303             0.28     0.794733            0.316156   \n",
       "\n",
       "   sum_all_reads  num_gap_bars  scale_rate_5p  num_mismatches_8mer  \\\n",
       "0   4.359565e-06      0.205128       0.205128                0.000   \n",
       "1   3.390773e-05      0.076923       0.076923                0.000   \n",
       "2   3.958582e-03      0.179487       0.179487                0.000   \n",
       "3   1.278806e-05      0.307692       0.307692                0.000   \n",
       "4   0.000000e+00      0.000000       0.000000                0.000   \n",
       "5   2.906377e-07      0.000000       0.000000                0.000   \n",
       "6   1.356309e-06      0.179487       0.179487                0.000   \n",
       "7   1.162551e-06      0.102564       0.102564                0.000   \n",
       "8   9.687922e-08      0.000000       0.000000                0.000   \n",
       "9   2.712618e-06      0.282051       0.282051                0.125   \n",
       "\n",
       "   num_mism_in_MB  len_after_MB       ...         hits_on_mature_miR  \\\n",
       "0             0.0      0.071429       ...                        0.0   \n",
       "1             0.0      0.190476       ...                        0.0   \n",
       "2             0.0      0.166667       ...                        1.0   \n",
       "3             0.0      0.190476       ...                        0.0   \n",
       "4             0.0      0.023810       ...                        0.0   \n",
       "5             0.0      0.000000       ...                        0.0   \n",
       "6             0.0      0.261905       ...                        0.0   \n",
       "7             0.0      0.214286       ...                        0.0   \n",
       "8             0.0      0.023810       ...                        1.0   \n",
       "9             0.0      0.142857       ...                        0.0   \n",
       "\n",
       "   bracket_mirna_fraction  hairpin_size_estimate  \\\n",
       "0                0.523810               0.297872   \n",
       "1                0.678571               0.765957   \n",
       "2                0.869565               0.585106   \n",
       "3                0.578947               0.489362   \n",
       "4                0.481481               0.627660   \n",
       "5                0.500000               0.638298   \n",
       "6                0.384615               0.384615   \n",
       "7                0.333333               0.191489   \n",
       "8                0.695652               0.585106   \n",
       "9                0.700000               0.340426   \n",
       "\n",
       "   loop_mirna_distance_estimate  loop_size_estimate  loops_in_hairpin  \\\n",
       "0                      0.000000            0.112676          0.000000   \n",
       "1                      0.285714            0.028169          0.000000   \n",
       "2                      0.171429            0.042254          0.000000   \n",
       "3                      0.000000            0.098592          0.111111   \n",
       "4                      0.200000            0.056338          0.000000   \n",
       "5                      0.000000            0.154930          0.111111   \n",
       "6                      0.384615            0.384615          0.384615   \n",
       "7                      0.000000            0.056338          0.000000   \n",
       "8                      0.142857            0.070423          0.000000   \n",
       "9                      0.000000            0.084507          0.000000   \n",
       "\n",
       "   minimum_free_energy  mirna_bracket_discrepancy  mirna_bracket_majority  \\\n",
       "0             0.582071                   1.000000                0.344828   \n",
       "1             0.443182                   1.000000                0.620690   \n",
       "2             0.608586                   1.000000                0.655172   \n",
       "3             0.880051                   1.000000                0.344828   \n",
       "4             0.747475                   1.000000                0.413793   \n",
       "5             0.897727                   1.000000                0.344828   \n",
       "6             0.384615                   0.384615                0.384615   \n",
       "7             0.551768                   0.636364                0.206897   \n",
       "8             0.571970                   1.000000                0.517241   \n",
       "9             0.467172                   1.000000                0.448276   \n",
       "\n",
       "   mirna_unmatched  \n",
       "0         0.344828  \n",
       "1         0.310345  \n",
       "2         0.103448  \n",
       "3         0.275862  \n",
       "4         0.482759  \n",
       "5         0.379310  \n",
       "6         0.384615  \n",
       "7         0.344828  \n",
       "8         0.241379  \n",
       "9         0.206897  \n",
       "\n",
       "[10 rows x 34 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_NaN = Imputer(missing_values=np.nan, strategy='median', axis=1)\n",
    "imputed_DF = pd.DataFrame(fill_NaN.fit_transform(data))\n",
    "imputed_DF.columns = data.columns\n",
    "imputed_DF.index = data.index\n",
    "data = imputed_DF\n",
    "\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-integrate TP label with the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_idx = y[ y == 1]\n",
    "y_idx\n",
    "\n",
    "ss = np.random.choice(y_idx.index, int(len(y)/2))\n",
    "ss\n",
    "y[ss] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_seq_len</th>\n",
       "      <th>MainBody_length</th>\n",
       "      <th>avg_GC_cont</th>\n",
       "      <th>avg_ATcont_after3p</th>\n",
       "      <th>sum_all_reads</th>\n",
       "      <th>num_gap_bars</th>\n",
       "      <th>scale_rate_5p</th>\n",
       "      <th>num_mismatches_8mer</th>\n",
       "      <th>num_mism_in_MB</th>\n",
       "      <th>len_after_MB</th>\n",
       "      <th>...</th>\n",
       "      <th>bracket_mirna_fraction</th>\n",
       "      <th>hairpin_size_estimate</th>\n",
       "      <th>loop_mirna_distance_estimate</th>\n",
       "      <th>loop_size_estimate</th>\n",
       "      <th>loops_in_hairpin</th>\n",
       "      <th>minimum_free_energy</th>\n",
       "      <th>mirna_bracket_discrepancy</th>\n",
       "      <th>mirna_bracket_majority</th>\n",
       "      <th>mirna_unmatched</th>\n",
       "      <th>TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.413838</td>\n",
       "      <td>0.050079</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.582071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912911</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.591125</td>\n",
       "      <td>0.102274</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.443182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.578872</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.464437</td>\n",
       "      <td>0.018967</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.274331</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.480594</td>\n",
       "      <td>0.091386</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.880051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.627660</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_seq_len  MainBody_length  avg_GC_cont  avg_ATcont_after3p  \\\n",
       "0     0.433333             0.36     0.413838            0.050079   \n",
       "1     0.912911             0.48     0.591125            0.102274   \n",
       "2     0.578872             0.44     0.464437            0.018967   \n",
       "3     0.274331             0.30     0.480594            0.091386   \n",
       "4     0.883333             0.50     0.509259            0.000000   \n",
       "\n",
       "   sum_all_reads  num_gap_bars  scale_rate_5p  num_mismatches_8mer  \\\n",
       "0       0.000004      0.205128       0.205128                  0.0   \n",
       "1       0.000034      0.076923       0.076923                  0.0   \n",
       "2       0.003959      0.179487       0.179487                  0.0   \n",
       "3       0.000013      0.307692       0.307692                  0.0   \n",
       "4       0.000000      0.000000       0.000000                  0.0   \n",
       "\n",
       "   num_mism_in_MB  len_after_MB ...  bracket_mirna_fraction  \\\n",
       "0             0.0      0.071429 ...                0.523810   \n",
       "1             0.0      0.190476 ...                0.678571   \n",
       "2             0.0      0.166667 ...                0.869565   \n",
       "3             0.0      0.190476 ...                0.578947   \n",
       "4             0.0      0.023810 ...                0.481481   \n",
       "\n",
       "   hairpin_size_estimate  loop_mirna_distance_estimate  loop_size_estimate  \\\n",
       "0               0.297872                      0.000000            0.112676   \n",
       "1               0.765957                      0.285714            0.028169   \n",
       "2               0.585106                      0.171429            0.042254   \n",
       "3               0.489362                      0.000000            0.098592   \n",
       "4               0.627660                      0.200000            0.056338   \n",
       "\n",
       "   loops_in_hairpin  minimum_free_energy  mirna_bracket_discrepancy  \\\n",
       "0          0.000000             0.582071                        1.0   \n",
       "1          0.000000             0.443182                        1.0   \n",
       "2          0.000000             0.608586                        1.0   \n",
       "3          0.111111             0.880051                        1.0   \n",
       "4          0.000000             0.747475                        1.0   \n",
       "\n",
       "   mirna_bracket_majority  mirna_unmatched  TP  \n",
       "0                0.344828         0.344828   0  \n",
       "1                0.620690         0.310345   0  \n",
       "2                0.655172         0.103448   0  \n",
       "3                0.344828         0.275862   0  \n",
       "4                0.413793         0.482759   0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TP'] = y\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split df into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples is 417188\n",
      "Number of testing samples is 104297\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.8\n",
    "\n",
    "sample = np.random.choice(data.index, size=int(len(data)*split_ratio), replace=False)\n",
    "train_data, test_data = data.iloc[sample], data.drop(sample)\n",
    "\n",
    "print(\"Number of training samples is\", len(train_data))\n",
    "print(\"Number of testing samples is\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create np.arrays for X_train/test and y_train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in X_train:  417188\n",
      "Number of rows in y_train:  417188\n",
      "Number of rows in X_test 104297\n",
      "Number of rows in y_test 104297\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(train_data.drop('TP', axis=1))\n",
    "y_train = np.array(keras.utils.to_categorical(train_data['TP'], 2))\n",
    "\n",
    "X_test = np.array(test_data.drop('TP', axis=1))\n",
    "y_test = np.array(keras.utils.to_categorical(test_data['TP'], 2))\n",
    "\n",
    "\n",
    "print(\"Number of rows in X_train: \", len(X_train))\n",
    "print(\"Number of rows in y_train: \", len(y_train))\n",
    "print(\"Number of rows in X_test\", len(X_test))\n",
    "print(\"Number of rows in y_test\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model using optimal parameters <span style='font-size:12px'>(found via GridSearchCV)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# create the model\n",
    "def create_model(optimizer='adam'):\n",
    "    \n",
    "    init_mode = 'he_normal'\n",
    "    reglr = 0.01\n",
    "#     optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    \n",
    "    # Building the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=regularizers.l2(reglr)))\n",
    "    model.add(Dropout(.4))\n",
    "    model.add(Dense(32, kernel_initializer=init_mode, activation='relu', kernel_regularizer=regularizers.l2(reglr)))\n",
    "    model.add(Dropout(.4))\n",
    "\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 333750 samples, validate on 83438 samples\n",
      "Epoch 1/30\n",
      "333750/333750 [==============================] - 5s 16us/step - loss: 0.1733 - acc: 0.9684 - val_loss: 0.1080 - val_acc: 0.9696\n",
      "Epoch 2/30\n",
      "333750/333750 [==============================] - 5s 14us/step - loss: 0.1090 - acc: 0.9697 - val_loss: 0.1031 - val_acc: 0.9696\n",
      "Epoch 3/30\n",
      "333750/333750 [==============================] - 5s 14us/step - loss: 0.1043 - acc: 0.9697 - val_loss: 0.1002 - val_acc: 0.9696\n",
      "Epoch 4/30\n",
      "333750/333750 [==============================] - 5s 15us/step - loss: 0.1013 - acc: 0.9697 - val_loss: 0.0985 - val_acc: 0.9696\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='acc', patience=2)] # do not apply without checking first with no callbacks\n",
    "\n",
    "out = model.fit(X_train, y_train, epochs=30, batch_size=128, verbose=1, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# larger model - deprecated\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "if(0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1000, activation='relu', input_shape=(X_train.shape[1],) ))\n",
    "    model.add(Dense(1000, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1000, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(500, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1000, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "    model.fit(X_train, y_train, callbacks=[early_stopping_monitor], validation_split=0.2, batch_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot training / validation loss and accuracy change at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAE/CAYAAADBgV1jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xt8VOW97/HPbyaTewghhPsduQSQIkZqqyJ4K+Cu9qIttrvd9LTa2ro97dn2SO3uduupbru1rbXb7i2edp/WY2s5tra2grd6q91eCKhUCMgtQAAhJCH3e57zxwyQhAlZIZOsmcn3/XrNi5m1nlnzWwzkm+dZ61nLnHOIiIgkg4DfBYiIiMSKQk1ERJKGQk1ERJKGQk1ERJKGQk1ERJKGQk1ERJKGQk1ERJKGQk1kEJlZqZld5ncdIslKoSYiIklDoSYSB8zsejPbaWaVZvakmY2LLDcz+6GZHTGzajPbbGbzIutWmNlWM6s1swNmdou/eyHiP4WaiM/M7BLgX4BPAWOBvcBjkdVXAIuBmcBw4NNARWTdT4EvO+dygHnAC4NYtkhcSvG7ABHhs8DPnHObAMzsW0CVmU0BWoEcYDbwpnOupNP7WoE5ZvaOc64KqBrUqkXikHpqIv4bR7h3BoBzro5wb2y8c+4F4N+AB4HDZrbGzIZFmn4SWAHsNbOXzexDg1y3SNxRqIn47yAw+fgLM8sC8oEDAM65B5xz5wJzCQ9DfjOyfINz7mpgFPA7YO0g1y0SdxRqIoMvZGbpxx+Ew+gLZrbAzNKAu4E3nHOlZnaemX3QzEJAPdAEtJtZqpl91sxynXOtQA3Q7tseicQJhZrI4FsHNHZ6XAR8B/gNcAiYDqyMtB0GPEz4eNlewsOS90XWfQ4oNbMa4CvA3w5S/SJxy3STUBERSRbqqYmISNJQqImISNJQqImISNJQqImISNJQqImISNKIu8tkjRw50k2ZMsXvMkREJI5s3LjxqHOuoLd2cRdqU6ZMobi42O8yREQkjpjZ3t5bafhRRESSiEJNRESShkJNRESSRtwdU4umtbWVsrIympqa/C4laaSnpzNhwgRCoZDfpYiIxExChFpZWRk5OTlMmTIFM/O7nITnnKOiooKysjKmTp3qdzkiIjGTEMOPTU1N5OfnK9BixMzIz89Xz1dEkk5ChBqgQIsx/X2KSDJKmFDz27Fjx/jJT37S5/etWLGCY8eOnbbNP/3TP/H888+faWkiIhKhUPOop1Brbz/9zYbXrVvH8OHDT9vmzjvv5LLLLutXfSIikqSh1tzaTmV9c0y3uXr1anbt2sWCBQs477zzWLp0KZ/5zGc4++yzAfjYxz7Gueeey9y5c1mzZs2J902ZMoWjR49SWlpKYWEh119/PXPnzuWKK66gsbERgFWrVvH444+faH/77bezcOFCzj77bLZt2wZAeXk5l19+OQsXLuTLX/4ykydP5ujRozHdRxGRRJeUoVZR38KBqiaaWk/fi+qLe+65h+nTp/P2229z77338uabb3LXXXexdetWAH72s5+xceNGiouLeeCBB6ioqDhlGzt27OBrX/saW7ZsYfjw4fzmN7+J+lkjR45k06ZN3Hjjjdx3330A3HHHHVxyySVs2rSJj3/84+zbty9m+yYikiwS4pT+zu74wxa2Hqw5bRsHNLa0ETAjPRTsdZtzxg3j9o/O7VMdixYt6nI6/AMPPMATTzwBwP79+9mxYwf5+fld3jN16lQWLFgAwLnnnktpaWnUbX/iE5840ea3v/0tAK+++uqJ7S9btoy8vLw+1SsiMhQkXKh5YUAoGKClrYP2DkcwEPsz/bKysk48f+mll3j++ed57bXXyMzMZMmSJVFPl09LSzvxPBgMnhh+7KldMBikra0NCM8tExGR00u4UPPao+rocLx3uJZgwDhrVHa/T2HPycmhtrY26rrq6mry8vLIzMxk27ZtvP766/36rGguvPBC1q5dy6233sqzzz5LVVVVzD9DRCTRJeUxNYBAwBiTm05jaztVDa393l5+fj4XXHAB8+bN45vf/GaXdcuWLaOtrY358+fzne98h/PPP7/fn9fd7bffzrPPPsvChQtZv349Y8eOJScnJ+afIyKSyCzehrWKiopc9/uplZSUUFhY2OdtOefYVV5Pa3sHs0bnEBiAYcjB0tzcTDAYJCUlhddee40bb7yRt99+u1/bPNO/VxGRwWZmG51zRb21S7jhx74wM8bmprOrvI7yumZGD0v3u6Qztm/fPj71qU/R0dFBamoqDz/8sN8liYjEHU+hZmbLgB8BQeB/O+fu6bZ+MXA/MB9Y6Zx7PLJ8KfDDTk1nR9b/Lga1e5KVlkJuRojy2mZGZKUSCibmiOuMGTN46623/C5DRCSu9foT3syCwIPAcmAOcJ2ZzenWbB+wCvhl54XOuRedcwuccwuAS4AG4NkY1N0nY4al4xwcrtEFfEVEkpmXbssiYKdzbrdzrgV4DLi6cwPnXKlzbjPQcZrtXAOsd841nHG1ZygtFCQ/O5Wq+paYTsgWEZH44iXUxgP7O70uiyzrq5XAr87gfTExKieNQMA4VK3emohIsvISatFOGezTKZNmNhY4G3imh/U3mFmxmRWXl5f3ZdOepQQDjMpJp7apldqm/p/iLyIi8cdLqJUBEzu9ngAc7OPnfAp4wjkXNU2cc2ucc0XOuaKCgoI+btq7/OxUUlMCHKpuGvArdGRnZwNw8OBBrrnmmqhtlixZQvfpC93df//9NDScHLH1cisbEZGhykuobQBmmNlUM0slPIz4ZB8/5zp8HHo8LmDGmGHpNMVoQrYX48aNO3EF/jPRPdS83MpGRGSo6jXUnHNtwE2Ehw5LgLXOuS1mdqeZXQVgZueZWRlwLfCQmW05/n4zm0K4p/dy7Mvvu9yMEJmpKRyuaaK9w3tv7dZbb+1yP7V//ud/5o477uDSSy89cZuY3//+96e8r7S0lHnz5gHQ2NjIypUrmT9/Pp/+9Ke7XPvxxhtvpKioiLlz53L77bcD4YskHzx4kKVLl7J06VLg5K1sAH7wgx8wb9485s2bx/3333/i83q6xY2ISNJzzsXV49xzz3Xdbd269ZRl/VHX1Ore2V/l3q9u9PyeTZs2ucWLF594XVhY6Pbu3euqq6udc86Vl5e76dOnu46ODuecc1lZWc455/bs2ePmzp3rnHPu+9//vvvCF77gnHPunXfeccFg0G3YsME551xFRYVzzrm2tjZ38cUXu3feecc559zkyZNdeXn5ic89/rq4uNjNmzfP1dXVudraWjdnzhy3adMmt2fPHhcMBt1bb73lnHPu2muvdY888kjUfYr136uIyEABip2HDEm8K4qsXw3v/7Vfm8gCZra1097h6EgNEhgzH5bfc9r3nHPOORw5coSDBw9SXl5OXl4eY8eO5Rvf+AavvPIKgUCAAwcOcPjwYcaMGRN1G6+88go333wzAPPnz2f+/Pkn1q1du5Y1a9bQ1tbGoUOH2Lp1a5f13b366qt8/OMfP3G3gE984hP8+c9/5qqrrvJ8ixsRkWSTeKEWI6nBAA0d7bS2dZDWe3MArrnmGh5//HHef/99Vq5cyaOPPkp5eTkbN24kFAoxZcqUqLec6Sza3QL27NnDfffdx4YNG8jLy2PVqlW9bsed5kQXr7e4ERFJNokXar30qLwKADXHGjla18yMUTlkeHjPypUruf766zl69Cgvv/wya9euZdSoUYRCIV588UX27t172vcvXryYRx99lKVLl/Luu++yefNmAGpqasjKyiI3N5fDhw+zfv16lixZApy85c3IkSNP2daqVatYvXo1zjmeeOIJHnnkkTP4mxARSR6JF2oxNConjaqGFg5VNzJ1ZFav91ybO3cutbW1jB8/nrFjx/LZz36Wj370oxQVFbFgwQJmz5592vffeOONfOELX2D+/PksWLCARYsWAfCBD3yAc845h7lz5zJt2jQuuOCCE++54YYbWL58OWPHjuXFF188sXzhwoWsWrXqxDa+9KUvcc4552ioUUSGtKS+9YwX5bXNHKpuZMrILIalhwbkM+KVbj0jIonC661nEvOS9TGUn51KWkqA948N/IRsEREZWEM+1AIWvkN2U1s7lfUtfpcjIiL9MORDDWBYeois1BQO1zT3aUK2iIjEl4QJtYEcGjx+h+y2jg7Ka5sH7HPiiYZaRSQZJUSopaenU1FRMaA/iDPTUhiekcrRumZa2k53W7jE55yjoqKC9PR0v0sREYmphDilf8KECZSVlTFQt6U5rq2jg8M1zdQcCpKXlTqgn+W39PR0JkyY4HcZIiIxlRChFgqFmDp16qB81h/Xl7Dmld384aYLmTc+d1A+U0REYiMhhh8H01eXnMXwjBB3PVWi404iIglGodZNbkaIr182k9d2V/DCtiN+lyMiIn2gUIviMx+cxLSRWdy9roTW9uQ+aUREJJko1KIIBQOsXj6bXeX1PLZhv9/liIiIRwq1Hlw+ZzQfnDqC+597j9qmVr/LERERDxRqPTAzvn1lIRX1Lfz7S7v8LkdERDxQqJ3G/AnD+fg54/npq3s4cEw32hQRiXcKtV7c8pFZANz3zHafKxERkd4o1HoxfngGX7xwKk+8dYDNZcf8LkdERE5DoebBjUumk5+Vync1IVtEJK4p1DzISQ/x9ctn8uaeSp7betjvckREpAcKNY+uO28i0wuyuGf9Nk3IFhGJUwo1j1KCAW5bUcjuo/X88o19fpcjIiJReAo1M1tmZtvNbKeZrY6yfrGZbTKzNjO7ptu6SWb2rJmVmNlWM5sSm9IH3yWzR/Hh6fnc//x7VDdqQraISLzpNdTMLAg8CCwH5gDXmdmcbs32AauAX0bZxC+Ae51zhcAiIGGvEnx8QvaxxlZ+8uJOv8sREZFuvPTUFgE7nXO7nXMtwGPA1Z0bOOdKnXObgS4HmyLhl+Kcey7Srs451xCb0v0xd1wunzhnAv/5l1L2Vyb0roiIJB0voTYe6HxV37LIMi9mAsfM7Ldm9paZ3Rvp+XVhZjeYWbGZFQ/03a1j4ZaPzCQQgH/VhGwRkbjiJdQsyjKvk7VSgIuAW4DzgGmEhym7bsy5Nc65IudcUUFBgcdN+2dsbgbXXzSNP7xzkLf2VfldjoiIRHgJtTJgYqfXE4CDHrdfBrwVGbpsA34HLOxbifHpyxdPZ2R2mu6QLSISR7yE2gZghplNNbNUYCXwpMftbwDyzOx49+sSYGvfy4w/2Wkp/MMVMyneW8XT777vdzkiIoKHUIv0sG4CngFKgLXOuS1mdqeZXQVgZueZWRlwLfCQmW2JvLed8NDjn8zsr4SHMh8emF0ZfNeeO4GZo7O55+lttLRpQraIiN8s3obOioqKXHFxsd9lePbS9iOs+s8NfOdv5vDFC6f6XY6ISFIys43OuaLe2umKIv108cwCLpoxkgf+tIPqBk3IFhHxk0Ktn8yM21YUUtPUyo9f2OF3OSIiQ5pCLQYKxw7jU+dO5OevlbK3ot7vckREhiyFWoz8jytmkhII8K9Pa0K2iIhfFGoxMnpYOl++eBpP/fUQG/dW+l2OiMiQpFCLoRsWT2NUTprukC0i4hOFWgxlpqZwyxWzeGvfMZ766yG/yxERGXIUajH2yXMnMHtMDt97ehvNbe1+lyMiMqQo1GIsGAjfc21/ZSO/+K+9fpcjIjKkKNQGwEUzClgyq4Afv7CDqvoWv8sRERkyFGoD5LYVhdQ1t/GAJmSLiAwahdoAmTk6h0+fN4lHXtvLnqOakC0iMhgUagPoG5fPIC0lwPfWb/O7FBGRIUGhNoBG5aTzlYun8/SW93lzjyZki4gMNIXaAPvSRdMYMyydu57aSkeHJmSLiAwkhdoAy0gNcstHZvFOWTV/2HzQ73JERJKaQm0QfOKc8cwZO4x/fXo7Ta2akC0iMlAUaoMgEDD+8cpCDhxr5P/8V6nf5YiIJC2F2iD58FkjuXT2KB58YScVdc1+lyMikpQUaoPoWytm09Dazo/+pAnZIiIDQaE2iM4alcN1iyby6Bv72FVe53c5IiJJR6E2yL5+2UwyQkH+ZZ0mZIuIxJpCbZCNzE7jxiXTeb7kMK/tqvC7HBGRpKJQ88EXL5zK+OEZ3LVOE7JFRGLJU6iZ2TIz225mO81sdZT1i81sk5m1mdk13da1m9nbkceTsSo8kaWHgnzzI7N490ANv3v7gN/liIgkjV5DzcyCwIPAcmAOcJ2ZzenWbB+wCvhllE00OucWRB5X9bPepHHVB8Yxf0Iu9z6jCdkiIrHipae2CNjpnNvtnGsBHgOu7tzAOVfqnNsMdAxAjUkpEDBuW1HIoeomfvrqHr/LERFJCl5CbTywv9Prssgyr9LNrNjMXjezj0VrYGY3RNoUl5eX92HTie38aflcPmc0P3lxJ+W1mpAtItJfXkLNoizry9kNk5xzRcBngPvNbPopG3NujXOuyDlXVFBQ0IdNJ75vLZ9Nc1sH9z//nt+liIgkPC+hVgZM7PR6AuD5cvPOuYORP3cDLwHn9KG+pDetIJu/PX8yv3pzHzsO1/pdjohIQvMSahuAGWY21cxSgZWAp7MYzSzPzNIiz0cCFwBbz7TYZHXzpTPISkvhX3SHbBGRfuk11JxzbcBNwDNACbDWObfFzO40s6sAzOw8MysDrgUeMrMtkbcXAsVm9g7wInCPc06h1s2IrFRuWnoWL2w7wl92HvW7HBGRhGXOxdfk36KiIldcXOx3GYOuqbWdS7//MsMyQvzx7y8kGIh2KFNEZGgys42R8zNOS1cUiRPpoSC3Lp9NyaEafrupzO9yREQSkkItjnx0/lgWTBzOfc9up7FFE7JFRPpKoRZHzMJ3yD5c08zDf97tdzkiIglHoRZniqaMYPm8MfzHy7s4UtPkdzkiIglFoRaHbl02m9b2Dn6oCdkiIn2iUItDU0Zm8bnzp/DrDfvZ/r4mZIuIeKVQi1M3X3oW2Wkp3L2uxO9SREQShkItTg3PTOXmS2fw8nvlvPLe0LnIs4hIfyjU4tjnPjSZSSMyuXtdCe26Q7aISK8UanEsLSXIrctms+39Wh7fuL/3N4iIDHEKtTi34uwxnDs5j/uefY/65ja/yxERiWsKtThnZnz7ykLKa5tZ84omZIuInI5CLQEsnJTHlfPHsuaV3RzWhGwRkR4p1BLE6mWzae9w3PfMdr9LERGJWwq1BDFxRCZ/9+HJPL6pjK0Ha/wuR0QkLinUEshNS2eQmxHi7nUlxNt98ERE4oFCLYHkZoa4+ZIZvLrzKC9pQraIyCkUagnmb8+fzJT8TO5+qoS29g6/yxERiSsKtQSTmhJg9fJCdhyp49fFmpAtItKZQi0BfWTuaBZNGcEPn3uPOk3IFhE5QaGWgMyM264s5GhdC//x0i6/yxERiRsKtQS1YOJwrvrAOB7+824OVTf6XY6ISFxQqCWw/7lsFg64VxOyRUQAhVpCm5CXyX+7YCq/3XSAdw9U+12OiIjvPIWamS0zs+1mttPMVkdZv9jMNplZm5ldE2X9MDM7YGb/Foui5aSvLp3OiKxUvvvUVk3IFpEhr9dQM7Mg8CCwHJgDXGdmc7o12wesAn7Zw2b+F/DymZcpPRmWHuLrl83g9d2V/KnkiN/liIj4yktPbRGw0zm32znXAjwGXN25gXOu1Dm3GThlNrCZnQuMBp6NQb0SxXWLJjGtIIu715fQqgnZIjKEeQm18UDnWb5lkWW9MrMA8H3gm720u8HMis2suLxcl3/qq1AwwLeWF7K7vJ7H3tzndzkiIr7xEmoWZZnXgzdfBdY550576Qvn3BrnXJFzrqigoMDjpqWzywpHcf60Efzw+R3UNLX6XY6IiC+8hFoZMLHT6wnAQY/b/xBwk5mVAvcBnzeze/pUoXhiZnx7xRwq61v4d03IFpEhykuobQBmmNlUM0sFVgJPetm4c+6zzrlJzrkpwC3AL5xzp5w9KbFx9oRcPnHOeH766h7Kqhr8LkdEZND1GmrOuTbgJuAZoARY65zbYmZ3mtlVAGZ2npmVAdcCD5nZloEsWnp2y0dmYaA7ZIvIkGTxNrepqKjIFRcX+11GQrv3mW08+OIufv+1C/jAxOF+lyMi0m9mttE5V9RbO11RJAnduOQsRmancpfukC0iQ4xCLQllp6Xw9ctm8uaeSp7detjvckREBo1CLUmtPG8iZ43K5p7122hp04RsERkaFGpJKiUY4LYVs9lztJ5fvrHX73JERAaFQi2JLZ01igvOyudHf9pBdaMmZItI8lOoJTEz47YVhRxrbOUnL+70uxwRkQGnUEtyc8fl8smFE/jPv5Syv1ITskUkuSnUhoBbrphFIADfe3qb36WIiAwohdoQMCY3nRsumsYfNx9i074qv8sRERkwCrUh4ssXT6cgJ427ntKEbBFJXgq1ISIrLYV/uHwmG/dW8fS77/tdjojIgFCoDSHXFk1k1ugc7nlaE7JFJDkp1IaQYMC47cpC9lY08IvXSv0uR0Qk5hRqQ8zFMwu4aMZIfvzCTo41tPhdjohITCnUhqBvX1lIbVMrP35BE7JFJLko1Iag2WOG8amiifzitVL2VtT7XY6ISMwo1Iao/3H5TELBgCZki0hSUagNUaOGpfPlxdNZ99f32bi30u9yRERiQqE2hF2/eCqjh6XxXU3IFpEkoVAbwjJTU/iHK2bx1r5j/HHzIb/LERHpN4XaEPfJhROYPSaH7z29jea2dr/LERHpF4XaEBcMGP945RzKqhr5+X+V+l2OiEi/KNSEC2eMZOmsAn78wk6q6jUhW0QSl0JNAPjWikLqm9v40Z92+F2KiMgZ8xRqZrbMzLab2U4zWx1l/WIz22RmbWZ2Taflk81so5m9bWZbzOwrsSxeYmfm6BxWLprE/319L7vL6/wuR0TkjPQaamYWBB4ElgNzgOvMbE63ZvuAVcAvuy0/BHzYObcA+CCw2szG9bdoGRjfuGwmaSmakC0iictLT20RsNM5t9s51wI8BlzduYFzrtQ5txno6La8xTnXHHmZ5vHzxCcFOWncuGQ6z2w5zBu7K/wuR0Skz7yEzHhgf6fXZZFlnpjZRDPbHNnG95xzB6O0ucHMis2suLy83OumZQB88cJpjM1N5+51JXR0aEK2iCQWL6FmUZZ5/mnnnNvvnJsPnAX8nZmNjtJmjXOuyDlXVFBQ4HXTMgAyUoPccsUs3imr5g+bT/n9Q0QkrnkJtTJgYqfXE4A+/7SL9NC2ABf19b0yuD5+znjmjhvGvz69naZWTcgWkcThJdQ2ADPMbKqZpQIrgSe9bNzMJphZRuR5HnABsP1Mi5XBEQgY376ykAPHGvnPv5T6XY6IiGe9hppzrg24CXgGKAHWOue2mNmdZnYVgJmdZ2ZlwLXAQ2a2JfL2QuANM3sHeBm4zzn314HYEYmtD08fyWWFo/jJizupqGvu/Q0iInHA4u3q7EVFRa64uNjvMgTYeaSOj9z/Cp/94CTuvHqe3+WIyBBmZhudc0W9tdMp9tKjs0Zl85lFk3j0jX3sPKIJ2SIS/xRqclpfv2wGGaEg96wv8bsUEZFeKdTktPKz0/jq0uk8X3KE/9p11O9yREROS6EmvfpvF0xl/PAMTcgWkbinUJNepYeC/M9ls3j3QA2/e/uA3+WIiPRIoSaefHT+OOZPyOXeZ7bT2KIJ2SISnxRq4kkgYHx7RSGHqpv46au7/S5HRCQqhZp49sFp+VwxZzT//tIuyms1IVtE4o9CTfpk9fLZNLd18MPn3/O7FBGRUyjUpE+mFWTzt+dP5rE397HjcK3f5YiIdKFQkz67+dIZZKWlcPc6TcgWkfiiUJM+G5GVyt9fchYvbi/n1R2akC0i8UOhJmfk8x+awoS8DO5aV0K7JmSLSJxQqMkZSQ8FuXXZbEoO1fCbTWV+lyMiAijUpB/+Zv5YFkwczvef3U5DS5vf5YiIKNTkzJkZ3/mbQg7XNPPwK3v8LkdERKEm/XPu5BGsOHsMD72yiyM1TX6XIyJDnEJN+u3WZbNpbe/gB89pQraI+EuhJv02OT+Lz39oCmuL97Pt/Rq/yxGRIUyhJjHx95ecRU56iLvXbfO7FBEZwhRqEhPDM8MTsl95r5yX3yv3uxwRGaIUahIzn//QFCbnZ3L3U5qQLSL+UKhJzKSmBLh12Wy2H67l/xXv97scERmCFGoSU8vnjaFoch7ff+496ps1IVtEBpenUDOzZWa23cx2mtnqKOsXm9kmM2szs2s6LV9gZq+Z2RYz22xmn45l8RJ/zIxvX1lIeW0zD72iO2SLyODqNdTMLAg8CCwH5gDXmdmcbs32AauAX3Zb3gB83jk3F1gG3G9mw/tbtMS3cybl8Tfzx7LmlV28X60J2SIyeLz01BYBO51zu51zLcBjwNWdGzjnSp1zm4GObsvfc87tiDw/CBwBCmJSucS1W5fNpqMDvv/sdr9LEZEhxEuojQc6H/UviyzrEzNbBKQCu/r6Xkk8E0dksuqCKTy+qYwtB6v9LkdEhggvoWZRlvXpfG0zGws8AnzBOdcRZf0NZlZsZsXl5ZrjlCy+tvQscjNC3L2uBOd0ir+IDDwvoVYGTOz0egJw0OsHmNkw4CngH51zr0dr45xb45wrcs4VFRRodDJZ5GaE+O+XzuAvOyt4abt+WRGRgecl1DYAM8xsqpmlAiuBJ71sPNL+CeAXzrn/d+ZlSqL67AcnM3VkFnetK6Gt/ZROuohITPUaas65NuAm4BmgBFjrnNtiZnea2VUAZnaemZUB1wIPmdmWyNs/BSwGVpnZ25HHggHZE4lLqSkBVi+fzc4jdfxaE7JFZIBZvB3rKCoqcsXFxX6XITHknOPTD73O7qN1vHjLEnLSQ36XJCIJxsw2OueKemunK4rIgDs+IftoXQsPvawJ2SIycBRqMig+MHE4Vy8Yx8N/3s3BY41+lyMiSUqhJoPmmx+ZhQPue0YTskVkYCjUZNBMyMvkixdO5bdvHeDdA5qQLSKxp1CTQXXjkumMyErlu09t1YRsEYk5hZoMqmHpIb5x2Qxe313Jn0qO+F2OiCQZhZoMupWLJjGtIIu715fQqgnZIhJDCjUZdKFggNuWF7K7vJ5fvbl6ESLVAAARgElEQVTP73JEJIko1MQXlxaO4kPT8rn/+R3UNLX6XY6IJAmFmvji+ITsqoYWfvKi7kYkIrGhUBPfzBufy8fPGc/P/rKHsqoGv8sRkSSgUBNf3XLFLAy4VxOyRSQGFGriq3HDM7j+omn8/u2DvL3/mN/liEiCU6iJ776yZDojs1O5+yndIVtE+kehJr7LTkvhG5fP5M3SSp7ZctjvckQkgSnUJC58umgiM0Zlc8/6ElraNCFbRM6MQk3iQkowwG0rCimtaODRN/b6XY6IJCiFmsSNJbMKuPCskfzoTzuobtCEbBHpO4WaxA0z47YVhVQ3tvLgSzv9LkdEEpBCTeLKnHHDuGbhBP7PX0rZX6kJ2SLSNwo1iTv/cMUsggHje09v87sUEUkwCjWJO2Ny07l+8TT+uPkQm/ZV+V2OiCQQhZrEpS8vnkZBThrf/aPukC0i3inUJC5lpaVwyxUz2bTvGOvffd/vckQkQXgKNTNbZmbbzWynma2Osn6xmW0yszYzu6bbuqfN7JiZ/TFWRcvQcM25E5k9Jod71m+jua3d73JEJAH0GmpmFgQeBJYDc4DrzGxOt2b7gFXAL6Ns4l7gc/0rU4aiYCB8iv++ygYeeU0TskWkd156aouAnc653c65FuAx4OrODZxzpc65zcAp1zdyzv0JqI1FsTL0LJ5ZwOKZBfz4hZ0ca2jxuxwRiXNeQm08sL/T67LIMpFB8e0VhdQ2tfLjFzQhW0ROz0uoWZRlMT0dzcxuMLNiMysuLy+P5aYlCcwak8Onz5vIL14rpfRovd/liEgc8xJqZcDETq8nAAdjWYRzbo1zrsg5V1RQUBDLTUuS+MblMwkFA5qQLSKnleKhzQZghplNBQ4AK4HPDGhVIt2MyknnKxdP5wfPvcfHHvwLk0ZknnhMHJHJpPxMxgxLJxiINrAgIkNFr6HmnGszs5uAZ4Ag8DPn3BYzuxMods49aWbnAU8AecBHzewO59xcADP7MzAbyDazMuCLzrlnBmqHJHndsHgadc1tbDlYzdv7j/HUXw/R3nFyJDwUNMYPzwiHXJTQG5Ye8rF6ERkMFm9XaygqKnLFxcV+lyEJoK29g0PVTeyrbOjy2B95VHW7fU1uRqhr0HV6jB2eTiioaxGIxCsz2+icK+qtnZfhx8TzzmOw6wXImwojpp78M6sATMNTySIlGGBiJKAuiLK+pqn1RMCdDL1Gth6q4dmt79PafvIXumDAGJub3mPoDc8MYfq3IxL3kjPUat+H0r/A5rV0OVEzlAV5UyJBN6Vr4OVOhKCGp5LJsPQQc8flMndc7inr2jsch2uauvTujj9/vuQwR+u6zonLSUuJBGjGKcE3Pi+DtJTgYO2WiJxGcg8/tjbBsX1QtQeqSqFyT/h5ZeR1e/PJthaE4RO79u46B19admxqkoRQ39xGWVVj1NDbX9lAc9vJ6wyYwdhh6Sd6jd1Db2R2qnp5Iv3kdfgxuUPtdDo6oPZQp5Dr9mfTsa7tswpOHc7UsOaQ1NHhKK9rjhp2+yobOFzT3KV9Rih4IuQ69/SOL0sPqZcn0huFWn81VkXv3VXugZoDnDKseXxIU8OaQ15TaztlVceD7tTeXkNL14szj8pJ6xJynXt7o3LSCGiagohCbUB1HtY8HnZ9GdY8EYAa1hxqnHNU1LecDLmKBvZ3CsCD1Y10/i+ZmhJgYl5G1NCbOCKT7LTkPCwu0p1CzS8a1pR+aG5r5+CxplOmJ+yLBGBtc1uX9vlZqVHn5U0ckcHY3AxNRpekoVCLVzEb1pwEQf2WPpQ456hubD1lTt7xXt6BY42eJ6NPHJFJboaGxSVxKNQS0SnDmp3P2iz1OKwZCUENaw45mowuyUyhlmw0rCn91NNk9P2VDZRVNWgyusQ1hdpQ05dhzdTsU4c0jz/XsOaQdLrJ6PsrG6JORp8wIpNJmowug0ShJidpWFP6SZPRxW8KNfGmz8Oao7pOSdCw5pAXq8noo4elk5+dyoisVPX05BQKNYmNxqroc/G8DmseD0ANaw5ZfZ2MDpCdlsKIrHDA5Uf+HJF9/HnayWVZqeRnp5KZqn9byU6hJgMv2rDmiQAs1bCm9KrzZPQjNU1U1LdQVd9CRX0LlZFHRd3J5y3tHVG3kx4KkJ+VdiLoOj/yO4XfiEibYekpGgJNMEP71jMyOELpUDAz/OjudMOa7/72NMOaUe6goGHNpGVmjMxOY2R2Wq9tnXPUNbeFg66+hcpI2IUDsLlLEO48UkdlfQuNraf2AiE8hy8vs2vY5Z8mCIdnhHS5sgShnpr448SwZreTVnob1sybAtmjIWskZI6ErPxw6GWOhNRMP/ZE4lhjSzsV9c09BmFlfWvkz/Cy2qa2qNsJGCdCMFovcET2yVDMz0olLytV8/xiTD01iW8ZeTA+D8YvPHVdT8OaR3fAjue6Dmt2Fso8GXSZI8PBdyL8Ov+ZH/4zNVs9wCSXkRpkQmomE/K8/cLT0tZBVcPJIc/jgdg9FN87XEtlfQvHGlvpqV8wLD2F/Oy0UwOwh96h7tYQGwo1iT+nG9Z0DpproeEo1Ecex583VHR6XQ5HSsLP25qif04wLdzL6xyCp4RiwckQTBumEExyqSkBRg9LZ/SwdE/t2zscVQ3dj/2dHAo9foxwf2UDb+8/RlV9C20d0VMwKzXIiOPH/TJD4dDLjjIkmpXGiOxUslKDOi4YhUJNEosZpA8LP0ZM6729c9BSHwm6ik4BGAm+zssqdoRft9ZH31YwNRxwXYIvWihGeoPpwyGgIahkFgx0OiY4uvf2zjlqGtu6Dol2OSEmHIhHapvZ9n4tFfUttLRFPzkmNSUQ5Thgz0E4LGNonByjUJPkZhY+szItclzOi9bGSC+wvFvv72jXcKwqDT9vqe3hs4PRe3+nhGJkWUaeQjDJmRm5mSFyM0NMK+i9vXOO+pZ2KutaThuElfUtlFbUU1nXQn2UKRIAKQEj7/gxv8zOUyROBuLJodFwm0S8y4NCTaS7UEZ4+sHwid7atzaFw6/7MGh9edcQPPRO+M+m6ujbsQBkjIh+EkznY4HHX2eM0Ny/JGdmZKelkJ2WwqR8b8cFm1rbux4HrG/uMi3ieChuPVhDRV0zNT2cHGMGwzNCJ4c8s7oGYefl+dnhEExN8f+XMv2PEOmvUDrkjg8/vGhvjQRfeZRjgZ16g4e3hp83VvWwIQv37nrsDUYZEtVd2JNeeijIuOEZjBue4al9a3tHl7mB4RNiuvYKK+pb2FVex4bSFqoaWujhsCA56Sknzv48GX5p3HzpWYM2QV6hJjLYgiHIGRN+eNHeBo2VUU6KKe8agkd3QP1r4bYu+nEY0nOjnwTTU28wpff5Y5LYQsEAo4alM6oPJ8dUN7Z26QF2GRKN9A7LqhrZXFZNVUML37h8xgDvxUmeQs3MlgE/AoLA/3bO3dNt/WLgfmA+sNI593indX8H/GPk5Xedcz+PReEiQ0YwBbJHhR9edLRD47FOw59Ho58oU7kb9r8ZDkgX/TgMacO6BV33M0O7LQt56x1I4goG7MTw41ke/kk65wb1BJVeQ83MgsCDwOVAGbDBzJ50zm3t1GwfsAq4pdt7RwC3A0WEZ9NujLy3p/EUEemvQDByPC7fW/uOjvAVXroPg3YfEq0ug0Nvh193tEbfVigrykkw3XuDnY4XpmbFbr8lLg32GZdeemqLgJ3Oud0AZvYYcDVwItScc6WRdd3HPD4CPOecq4ysfw5YBvyq35WLSGwEApA5IvwY6WGYyDlorokefJ17g7WH4PC74ec9TZhPyTgZfBnDw6GY2tMjO/xnKPPk8xPLM8PLh8Ap63J6XkJtPLC/0+sy4IMetx/tvR6PpotIXDILH5tLz4X86b23dw5a6qKfFNN52sTxoGypP/noac5g9MK6hmB/ArJzm2CqwjKBeAm1aN+m1wtGenqvmd0A3AAwadIkj5sWkYRgBmk54ceIqX17b0cHtDaEHy11nQKvDloaOj0/HoJR2jVVQ83Brm176jlGE0jpJSAjARjqFoa9BammYwwIL3+rZUDnCTsTgIMet18GLOn23pe6N3LOrQHWQPiCxh63LSLJLhA4OXkejyfKeNHeFu4Fni4kTxuk9VB3pGu75rqeT7iJJpjWj4Ds3hPtFJhDfAK/l1DbAMwws6nAAWAl8BmP238GuNvM8iKvrwC+1ecqRURiKZgCwcgQaqw4B+0tXYdPPYdkp+WN+0/dhufBMToFYveA7ByS3YZdowVk5zYp6QkzBNtrqDnn2szsJsIBFQR+5pzbYmZ3AsXOuSfN7DzgCSAP+KiZ3eGcm+ucqzSz/0U4GAHuPH7SiIhIUjELz+tLSQufdBMrzoUv3XYmAXmiXR3UHe7arq2xD/sW6CEgo/QoTxmqzYazLh20if+6n5qIyFDU0X76Y5G9Dsf20CONNt3jtoP9nr6h+6mJiEjPAsGTd7yIpbaWU49XhgbvBr4KNRERiZ2U1PAjI6/3tgNgaJ8mIyIiSUWhJiIiSUOhJiIiSUOhJiIiSUOhJiIiSUOhJiIiSUOhJiIiSUOhJiIiSUOhJiIiSUOhJiIiSSPuLmhsZuXA3hhsaiRwNAbbSQRDaV9haO2v9jU5aV/7brJzrqC3RnEXarFiZsVeruicDIbSvsLQ2l/ta3LSvg4cDT+KiEjSUKiJiEjSSOZQW+N3AYNoKO0rDK391b4mJ+3rAEnaY2oiIjL0JHNPTUREhpiEDzUzW2Zm281sp5mtjrI+zcx+HVn/hplNGfwqY8PDvq4ys3Izezvy+JIfdcaCmf3MzI6Y2bs9rDczeyDyd7HZzBYOdo2x4mFfl5hZdafv9Z8Gu8ZYMbOJZvaimZWY2RYz++9R2iTFd+txX5PiuzWzdDN708zeiezrHVHaDM7PYudcwj6AILALmAakAu8Ac7q1+SrwH5HnK4Ff+133AO7rKuDf/K41Rvu7GFgIvNvD+hXAesCA84E3/K55APd1CfBHv+uM0b6OBRZGnucA70X5d5wU363HfU2K7zbyXWVHnoeAN4Dzu7UZlJ/Fid5TWwTsdM7tds61AI8BV3drczXw88jzx4FLzcwGscZY8bKvScM59wpQeZomVwO/cGGvA8PNbOzgVBdbHvY1aTjnDjnnNkWe1wIlwPhuzZLiu/W4r0kh8l3VRV6GIo/uJ2wMys/iRA+18cD+Tq/LOPUfzYk2zrk2oBrIH5TqYsvLvgJ8MjJk87iZTRyc0nzh9e8jWXwoMrSz3szm+l1MLESGn84h/Ft9Z0n33Z5mXyFJvlszC5rZ28AR4DnnXI/f60D+LE70UIuW8t1/O/DSJhF42Y8/AFOcc/OB5zn5W1EySpbv1YtNhC8R9AHgx8DvfK6n38wsG/gN8HXnXE331VHekrDfbS/7mjTfrXOu3Tm3AJgALDKzed2aDMr3muihVgZ07o1MAA721MbMUoBcEnOop9d9dc5VOOeaIy8fBs4dpNr84OW7TwrOuZrjQzvOuXVAyMxG+lzWGTOzEOEf8o86534bpUnSfLe97WuyfbcAzrljwEvAsm6rBuVncaKH2gZghplNNbNUwgcfn+zW5kng7yLPrwFecJEjlQmm133tdtzhKsJj+MnqSeDzkTPlzgeqnXOH/C5qIJjZmOPHHsxsEeH/txX+VnVmIvvxU6DEOfeDHpolxXfrZV+T5bs1swIzGx55ngFcBmzr1mxQfhanxHqDg8k512ZmNwHPED478GfOuS1mdidQ7Jx7kvA/qkfMbCfh3wpW+lfxmfO4rzeb2VVAG+F9XeVbwf1kZr8ifGbYSDMrA24nfPAZ59x/AOsInyW3E2gAvuBPpf3nYV+vAW40szagEViZoL+YAVwAfA74a+T4C8BtwCRIuu/Wy74my3c7Fvi5mQUJB/Na59wf/fhZrCuKiIhI0kj04UcREZETFGoiIpI0FGoiIpI0FGoiIpI0FGoiIpI0FGoiIpI0FGoiIpI0FGoiIpI0/j+lOYBN0QHtDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2e766470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2173f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = np.array(out.__dict__['epoch'])\n",
    "acc = np.array(out.__dict__['history']['acc'])\n",
    "loss = np.array(out.__dict__['history']['loss'])\n",
    "val_acc = np.array(out.__dict__['history']['val_acc'])\n",
    "val_loss = np.array(out.__dict__['history']['val_loss'])\n",
    "\n",
    "f = plt.figure(figsize=(7,5))\n",
    "plt.plot(epochs, loss, label='training')\n",
    "plt.plot(epochs, val_loss, label='validation')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "f = plt.figure(figsize=(7,5))\n",
    "plt.plot(epochs, acc, label='training')\n",
    "plt.plot(epochs, val_acc, label='validation')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "f.savefig(\"train_validation_loss.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model on the training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417188/417188 [==============================] - 8s 19us/step\n",
      "\n",
      " Training Accuracy: 0.969718687978\n",
      "104297/104297 [==============================] - 2s 19us/step\n",
      "\n",
      " Testing Accuracy: 0.970315541195\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(X_train, y_train, verbose=1)\n",
    "print(\"\\n Training Accuracy:\", train_score[1])\n",
    "test_score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"\\n Testing Accuracy:\", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98    101201\n",
      "          1       0.00      0.00      0.00      3096\n",
      "\n",
      "avg / total       0.94      0.97      0.96    104297\n",
      "\n",
      "[[101201      0]\n",
      " [  3096      0]]\n",
      "\n",
      "TP: 0\n",
      "FN: 3096\n",
      "TN: 101201\n",
      "FP: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dvitsios/anaconda3/envs/py3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y.values.argmax\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "p = model.predict_proba(X_test)\n",
    "\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred))\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))\n",
    "print()\n",
    "TN, FP, FN, TP = confusion_matrix(np.argmax(y_test, axis=1), y_pred).ravel()\n",
    "print(\"TP:\", TP)\n",
    "print(\"FN:\", FN)\n",
    "print(\"TN:\", TN)\n",
    "print(\"FP:\", FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect predicted positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_0</th>\n",
       "      <th>test_1</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.999819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.999809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.999782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.999754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.999693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.999798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.999714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.999731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.999802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.999795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.999783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.999795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.999788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.999737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.999766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.999812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.999818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.999728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.999670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.999816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.999834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.999781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.999806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.999784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.999810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.999769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.999828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.999682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.999821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.999829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104184</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.999809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104186</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.999800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104188</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.999801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104191</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.999712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104200</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.999726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104201</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.999777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104202</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.999833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104207</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.999797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104209</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.999732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104210</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.999782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104214</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.999809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104218</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.999779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104221</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.999710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104222</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.999807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104223</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.999704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104232</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.999810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.999778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.999662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104238</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.999810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104240</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.999774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104244</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.999810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104248</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.999744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104260</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.999705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104262</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.999819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104267</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.999789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.999807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.999775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104289</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.999810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104290</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.999731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104296</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.999699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25172 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        test_0  test_1    pred_0    pred_1\n",
       "10         0.0     1.0  0.000181  0.999819\n",
       "14         0.0     1.0  0.000191  0.999809\n",
       "20         0.0     1.0  0.000218  0.999782\n",
       "25         0.0     1.0  0.000246  0.999754\n",
       "27         0.0     1.0  0.000307  0.999693\n",
       "32         0.0     1.0  0.000202  0.999798\n",
       "38         0.0     1.0  0.000286  0.999714\n",
       "41         0.0     1.0  0.000269  0.999731\n",
       "45         0.0     1.0  0.000198  0.999802\n",
       "53         0.0     1.0  0.000205  0.999795\n",
       "54         0.0     1.0  0.000217  0.999783\n",
       "67         0.0     1.0  0.000205  0.999795\n",
       "73         0.0     1.0  0.000212  0.999788\n",
       "74         0.0     1.0  0.000263  0.999737\n",
       "76         0.0     1.0  0.000234  0.999766\n",
       "82         0.0     1.0  0.000188  0.999812\n",
       "88         0.0     1.0  0.000182  0.999818\n",
       "91         0.0     1.0  0.000272  0.999728\n",
       "93         0.0     1.0  0.000330  0.999670\n",
       "99         0.0     1.0  0.000184  0.999816\n",
       "108        0.0     1.0  0.000166  0.999834\n",
       "111        0.0     1.0  0.000219  0.999781\n",
       "115        0.0     1.0  0.000195  0.999806\n",
       "122        0.0     1.0  0.000216  0.999784\n",
       "124        0.0     1.0  0.000190  0.999810\n",
       "125        0.0     1.0  0.000231  0.999769\n",
       "131        0.0     1.0  0.000172  0.999828\n",
       "134        0.0     1.0  0.000318  0.999682\n",
       "139        0.0     1.0  0.000179  0.999821\n",
       "140        0.0     1.0  0.000171  0.999829\n",
       "...        ...     ...       ...       ...\n",
       "104184     0.0     1.0  0.000191  0.999809\n",
       "104186     0.0     1.0  0.000200  0.999800\n",
       "104188     0.0     1.0  0.000199  0.999801\n",
       "104191     0.0     1.0  0.000288  0.999712\n",
       "104200     0.0     1.0  0.000274  0.999726\n",
       "104201     0.0     1.0  0.000223  0.999777\n",
       "104202     0.0     1.0  0.000167  0.999833\n",
       "104207     0.0     1.0  0.000203  0.999797\n",
       "104209     0.0     1.0  0.000268  0.999732\n",
       "104210     0.0     1.0  0.000218  0.999782\n",
       "104214     0.0     1.0  0.000191  0.999809\n",
       "104218     0.0     1.0  0.000221  0.999779\n",
       "104221     0.0     1.0  0.000290  0.999710\n",
       "104222     0.0     1.0  0.000193  0.999807\n",
       "104223     0.0     1.0  0.000296  0.999704\n",
       "104232     0.0     1.0  0.000190  0.999810\n",
       "104235     0.0     1.0  0.000222  0.999778\n",
       "104236     0.0     1.0  0.000338  0.999662\n",
       "104238     0.0     1.0  0.000190  0.999810\n",
       "104240     0.0     1.0  0.000226  0.999774\n",
       "104244     0.0     1.0  0.000190  0.999810\n",
       "104248     0.0     1.0  0.000255  0.999744\n",
       "104260     0.0     1.0  0.000295  0.999705\n",
       "104262     0.0     1.0  0.000181  0.999819\n",
       "104267     0.0     1.0  0.000211  0.999789\n",
       "104275     0.0     1.0  0.000193  0.999807\n",
       "104276     0.0     1.0  0.000225  0.999775\n",
       "104289     0.0     1.0  0.000190  0.999810\n",
       "104290     0.0     1.0  0.000268  0.999731\n",
       "104296     0.0     1.0  0.000301  0.999699\n",
       "\n",
       "[25172 rows x 4 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conc = pd.concat([pd.DataFrame(y_test), pd.DataFrame(p)], axis=1)\n",
    "conc.columns = ['test_0', 'test_1', 'pred_0', 'pred_1']\n",
    "subdf = conc.loc[conc['test_1'] == 1]\n",
    "p = subdf.loc[subdf['pred_1'] >= 0.5]\n",
    "\n",
    "p[:15]\n",
    "subdf.loc[subdf['pred_1'] >= 0.5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
